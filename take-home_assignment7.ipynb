{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ceb8bd2",
   "metadata": {},
   "source": [
    "# **Data Science Bootcamp, Spring 2025**\n",
    "---\n",
    "**Take-Home Assignment #7** \\\n",
    "Cherron Griffith \\\n",
    "Due Date: April 20, 2025\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ee4c6",
   "metadata": {},
   "source": [
    "### **Logistic Regression**\n",
    "---\n",
    "1. Try different thresholds for computing predictions. By default it is 0.5. Use `predit_proba` function to compute probabilities and then try custom thresholds and see their impact on accuracy, precision, and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafec023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up data for model\n",
    "glass = pd.read_csv('glass.csv')\n",
    "glass.Type.value_counts().sort_index()\n",
    "glass['household'] = glass.Type.map({1:0, 2:0, 3:0, 5:1, 6:1, 7:1})\n",
    "glass.sort_values(by = 'Al', inplace = True)\n",
    "X = np.array(glass.Al).reshape(-1, 1)\n",
    "y = glass.household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdefa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "pred = logreg.predict(X)\n",
    "logreg.coef_, logreg.intercept_\n",
    "glass_probs = logreg.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d341da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3\n",
      "Accuracy: 0.8644859813084113\n",
      "Precision: 0.72\n",
      "Recall: 0.7058823529411765\n",
      "---\n",
      "Threshold: 0.5\n",
      "Accuracy: 0.8691588785046729\n",
      "Precision: 0.896551724137931\n",
      "Recall: 0.5098039215686274\n",
      "---\n",
      "Threshold: 0.7\n",
      "Accuracy: 0.8364485981308412\n",
      "Precision: 1.0\n",
      "Recall: 0.3137254901960784\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Apply different thresholds to make predictions \n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "for t in thresholds:\n",
    "    glass_pred = (glass_probs >= t).astype(int)\n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true = y, y_pred = glass_pred))\n",
    "    print(\"Precision:\", precision_score(y_true = y, y_pred = glass_pred))\n",
    "    print(\"Recall:\", recall_score(y_true = y, y_pred = glass_pred))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f6081",
   "metadata": {},
   "source": [
    "**Conclusion:** Lower thresholds have a decrease in precision and accuracy (slightly), and an increase in recall, while higher thresholds have an increase in precision, and a decrease accuracy and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514a322c",
   "metadata": {},
   "source": [
    "2. Do the same analysis for other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a620cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up data for model\n",
    "glass = pd.read_csv('glass.csv')\n",
    "glass.head()\n",
    "glass.Type.value_counts().sort_index()\n",
    "glass['window'] = glass.Type.map({1:1, 2:1, 3:1, 5:0, 6:0, 7:0})\n",
    "glass.sort_values( by = 'Al', inplace=True)\n",
    "X = np.array(glass.Al).reshape(-1,1)\n",
    "y = glass.window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725808c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "pred = logreg.predict(X)\n",
    "logreg.coef_, logreg.intercept_\n",
    "glass_probs = logreg.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728bfd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.3\n",
      "Accuracy: 0.8364485981308412\n",
      "Precision: 0.8232323232323232\n",
      "Recall: 1.0\n",
      "---\n",
      "Threshold: 0.5\n",
      "Accuracy: 0.8691588785046729\n",
      "Precision: 0.8648648648648649\n",
      "Recall: 0.9815950920245399\n",
      "---\n",
      "Threshold: 0.7\n",
      "Accuracy: 0.8644859813084113\n",
      "Precision: 0.9085365853658537\n",
      "Recall: 0.9141104294478528\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Apply different thresholds to make predictions \n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "for t in thresholds:\n",
    "    glass_pred = (glass_probs >= t).astype(int)\n",
    "    print(f\"Threshold: {t}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true = y, y_pred = glass_pred))\n",
    "    print(\"Precision:\", precision_score(y_true = y, y_pred = glass_pred))\n",
    "    print(\"Recall:\", recall_score(y_true = y, y_pred = glass_pred))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26812e89",
   "metadata": {},
   "source": [
    "**Conclusion:** Lower thresholds also have a decrease in precision and accuracy, and an increase in recall, while higher thresholds have an increase in precision, and a slight decrease accuracy and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080b994",
   "metadata": {},
   "source": [
    "3.  Fit a Logistic Regression Model on all features. Remember to preprocess data (ex: normalization and one hot encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a97c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = glass.drop(columns=['window'])\n",
    "y = glass.window\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc860aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "window_model = LogisticRegression()\n",
    "window_model.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities for class 1\n",
    "y_pred_probs = window_model.predict_proba(X_test)\n",
    "y_scores = y_pred_probs[:, 1]\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0fe03",
   "metadata": {},
   "source": [
    "4. Plot ROC Curves for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d575b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Calculate FPR, TPR, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6455a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve \n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6441a",
   "metadata": {},
   "source": [
    "### **Clustering**\n",
    "---\n",
    "1. Repeat the above exercise for different values of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d083ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn import cluster, datasets, preprocessing, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e66effdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2\n",
      "  Inertia: 12.14\n",
      "  Silhouette Score: 0.6295\n",
      "---\n",
      "k = 3\n",
      "  Inertia: 7.14\n",
      "  Silhouette Score: 0.4825\n",
      "---\n",
      "k = 4\n",
      "  Inertia: 6.18\n",
      "  Silhouette Score: 0.3792\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns[:-1]\n",
    "X_scaled = preprocessing.MinMaxScaler().fit_transform(df[cols])\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "k_values = range(2,5)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X_scaled)\n",
    "    \n",
    "    labels = kmeans.labels_\n",
    "    inertia = kmeans.inertia_\n",
    "    silhouette = silhouette_score(X_scaled, labels)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "    print(f\"k = {k}\")\n",
    "    print(f\"  Inertia: {inertia:.2f}\")\n",
    "    print(f\"  Silhouette Score: {silhouette:.4f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7604f",
   "metadata": {},
   "source": [
    "- **How do the inertia and silhouette scores change?**\n",
    "\n",
    "    Inertia and silhouette scores decreased as the k values increased.\n",
    "\n",
    "- **What if you don't scale your features?**\n",
    "\n",
    "    If you do not scale your features, features with larger numeric ranges would greatly affect the distance calculations and, therefore, also the clustering.\n",
    "\n",
    "- **Is there a \"right\" k? Why or why not?**\n",
    "\n",
    "    The \"right\" value for k depends on the data you are doing the clustering analysis on. Finding the \"right\" k for your data involves using the Elbow Method or the peak silhouette score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
